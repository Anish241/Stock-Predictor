{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 50000  \n",
    "MAX_SEQUENCE_LENGTH = 100  \n",
    "VALIDATION_SPLIT = 0.2  \n",
    "EMBEDDING_DIM = 100  \n",
    "LSTM_UNITS = 64  \n",
    "BATCH_SIZE = 32  \n",
    "EPOCHS = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  According to Gran , the company has no plans t...          2\n",
       "1  Technopolis plans to develop in stages an area...          2\n",
       "2  The international electronic industry company ...         -1\n",
       "3  With the new production plant the company woul...          1\n",
       "4  According to the company 's updated strategy f...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Dataset/df5.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive:  5048\n",
      "Negative:  2710\n",
      "Neutral:  2879\n"
     ]
    }
   ],
   "source": [
    "positive = []\n",
    "negative = []\n",
    "neutral = []\n",
    "for i in range(len(df)):\n",
    "    if df['Sentiment'][i] == 1:\n",
    "        positive.append(df['Text'][i])\n",
    "    elif df['Sentiment'][i] == 2:\n",
    "        neutral.append(df['Text'][i])\n",
    "    elif df['Sentiment'][i] == -1:\n",
    "        negative.append(df['Text'][i])\n",
    "    else:\n",
    "        print('error')\n",
    "\n",
    "print(\"Positive: \",len(positive))\n",
    "print(\"Negative: \",len(negative))\n",
    "print(\"Neutral: \",len(neutral))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability .\n",
      "The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported .\n",
      "According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .\n"
     ]
    }
   ],
   "source": [
    "print(positive[0])\n",
    "print(negative[0])\n",
    "print(neutral[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(positive + negative + neutral) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_poitive = tokenizer.texts_to_sequences(positive)\n",
    "sequence_negative = tokenizer.texts_to_sequences(negative)\n",
    "sequence_neutral = tokenizer.texts_to_sequences(neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17001 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pad_sequences(sequence_poitive + sequence_negative + sequence_neutral , maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate([np.ones(len(positive)), -np.ones(len(negative)),np.full(len(neutral),2)])\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (10637, 100)\n",
      "Shape of label tensor: (10637, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data[:-num_validation_samples]\n",
    "y_train = labels[:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = labels[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(Bidirectional(LSTM(LSTM_UNITS, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('news_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.9671\n",
      "Epoch 1: val_accuracy improved from -inf to 0.77057, saving model to news_model.h5\n",
      "266/266 [==============================] - 32s 120ms/step - loss: 0.0960 - accuracy: 0.9671 - val_loss: 0.7079 - val_accuracy: 0.7706\n",
      "Epoch 2/10\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.9792\n",
      "Epoch 2: val_accuracy did not improve from 0.77057\n",
      "266/266 [==============================] - 35s 130ms/step - loss: 0.0596 - accuracy: 0.9792 - val_loss: 0.7767 - val_accuracy: 0.7673\n",
      "Epoch 3/10\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 0.9878\n",
      "Epoch 3: val_accuracy did not improve from 0.77057\n",
      "266/266 [==============================] - 34s 128ms/step - loss: 0.0424 - accuracy: 0.9878 - val_loss: 0.8674 - val_accuracy: 0.7682\n",
      "Epoch 4/10\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.9915\n",
      "Epoch 4: val_accuracy did not improve from 0.77057\n",
      "266/266 [==============================] - 35s 133ms/step - loss: 0.0283 - accuracy: 0.9915 - val_loss: 1.0295 - val_accuracy: 0.7687\n",
      "Epoch 5/10\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9945\n",
      "Epoch 5: val_accuracy did not improve from 0.77057\n",
      "266/266 [==============================] - 36s 134ms/step - loss: 0.0203 - accuracy: 0.9945 - val_loss: 1.0652 - val_accuracy: 0.7621\n",
      "Epoch 6/10\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9967\n",
      "Epoch 6: val_accuracy did not improve from 0.77057\n",
      "266/266 [==============================] - 34s 128ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 1.2413 - val_accuracy: 0.7612\n",
      "Epoch 7/10\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9948\n",
      "Epoch 7: val_accuracy did not improve from 0.77057\n",
      "266/266 [==============================] - 36s 134ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 1.2952 - val_accuracy: 0.7579\n",
      "Epoch 8/10\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9955\n",
      "Epoch 8: val_accuracy did not improve from 0.77057\n",
      "266/266 [==============================] - 40s 151ms/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 1.2302 - val_accuracy: 0.7602\n",
      "Epoch 9/10\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9973\n",
      "Epoch 9: val_accuracy did not improve from 0.77057\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0116 - accuracy: 0.9973 - val_loss: 1.5110 - val_accuracy: 0.7649\n",
      "Epoch 10/10\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9955\n",
      "Epoch 10: val_accuracy did not improve from 0.77057\n",
      "266/266 [==============================] - 33s 123ms/step - loss: 0.0157 - accuracy: 0.9955 - val_loss: 1.4956 - val_accuracy: 0.7588\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(x_val, y_val), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('news_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Reliance industries goes bankrupt\"\n",
    "sequence = tokenizer.texts_to_sequences([sentence])\n",
    "data = pad_sequences(sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "result = model.predict(data)\n",
    "print(np.argmax(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km²)</th>\n",
       "      <th>Density (P/Km²)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment Time of Tweet Age of User  \\\n",
       "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
       "1                             Sooo SAD  negative          noon       21-30   \n",
       "2                          bullying me  negative         night       31-45   \n",
       "3                       leave me alone  negative       morning       46-60   \n",
       "4                        Sons of ****,  negative          noon       60-70   \n",
       "\n",
       "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n",
       "0  Afghanistan          38928346         652860.0               60  \n",
       "1      Albania           2877797          27400.0              105  \n",
       "2      Algeria          43851044        2381740.0               18  \n",
       "3      Andorra             77265            470.0              164  \n",
       "4       Angola          32866272        1246700.0               26  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('../Dataset/T/train.csv',encoding='latin-1')\n",
    "df1.head()\n",
    "df1.text = df1.text.astype(str)\n",
    "df1.selected_text = df1.selected_text.astype(str)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive:  8582\n",
      "Negative:  7781\n",
      "Neutral:  11118\n"
     ]
    }
   ],
   "source": [
    "positive = []\n",
    "negative = []\n",
    "neutral = []\n",
    "for i in range(len(df1)):\n",
    "    if df1['sentiment'][i] == \"positive\":\n",
    "        positive.append(df1['selected_text'][i])\n",
    "    elif df1['sentiment'][i] == \"neutral\":\n",
    "        neutral.append(df1['selected_text'][i])\n",
    "    elif df1['sentiment'][i] == \"negative\":\n",
    "        negative.append(df1['selected_text'][i])\n",
    "    else:\n",
    "        print('error')\n",
    "\n",
    "print(\"Positive: \",len(positive))\n",
    "print(\"Negative: \",len(negative))\n",
    "print(\"Neutral: \",len(neutral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fun\n"
     ]
    }
   ],
   "source": [
    "print(positive[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(positive + negative + neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_poitive = tokenizer.texts_to_sequences(positive)\n",
    "sequence_negative = tokenizer.texts_to_sequences(negative)\n",
    "sequence_neutral = tokenizer.texts_to_sequences(neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17819 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pad_sequences(sequence_poitive + sequence_negative + sequence_neutral , maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "labels = np.concatenate([np.ones(len(positive)), np.full(len(negative),-1),np.full(len(neutral),2)])\n",
    "\n",
    "labels = to_categorical(labels)\n",
    "print(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (27481, 100)\n",
      "Shape of label tensor: (27481, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = labels[:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = labels[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(Bidirectional(LSTM(LSTM_UNITS, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('news_model_4.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(x_val, y_val), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GoogleNews import GoogleNews\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 429: Too Many Requests\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('https://www.google.com/', headers = {'User-agent': 'your bot 0.1'})\n",
    "googlenews=GoogleNews(start='8/01/2023',end='8/04/2023')\n",
    "googlenews.search('Punjab National Bank')\n",
    "result=googlenews.result()\n",
    "dfn=pd.DataFrame(result)\n",
    "dfn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LUCKNOW: The Central Bureau of Investigation (CBI) on Tuesday arrested a branch manager and a field officer, both working at Punjab National Bank in Uttar...', 'The Central Bureau of Investigation has arrested a Branch Manager and a Field Officer, both working in Punjab National Bank, Khekra, Bagpat(Uttar Pradesh)...', 'The Central Bureau of Investigation has arrested a Branch Manager and a Field Officer of Punjab National Bank, Bagpat in Uttar Pradesh for demanding and...', 'The current trading price of PNB is 61.2 Rs, which is lower than the S2 level of 62.816666 Rs. 12:18 PM IST. Punjab National Bank Share Price Live Updates:...', 'Punjab National Bank (PNB) is conducting an electronic auction (e-auction) for mortgage properties on 3 August 2023. The properties offered by the PNB...', 'Your account may be restricted. Update KYC soon. Check last date. Punjab National Bank KYC Update News (Last Date, Documents Required): PNB has asked its...', 'Punjab National Bank (PNB) Share Price. Sector: Banks (Large Cap); Volume: 30729374. Aug 01,...', 'On the other hand, IndusInd Bank(down 1.63 per cent), State Bank of India(down 1.35 per cent), AU Small Finance Bank(down 1.12 per cent), Punjab National Bank(...', 'The company, promoted by Punjab National Bank, has an aggressive growth plan and has set an internal target of crossing the Rs 1 lakh crore-mark on the...', 'Reliance industries goes bankrupt']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titles = []\n",
    "for i in range(len(dfn)):\n",
    "    titles.append(dfn['desc'][i])\n",
    "    \n",
    "\n",
    "titles.append(\"Reliance industries goes bankrupt\")\n",
    "print(titles)\n",
    "\n",
    "print(len(titles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPred(sentence):\n",
    "    sequence = tokenizer.texts_to_sequences([sentence])\n",
    "    data = pad_sequences(sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    result = model.predict(data)\n",
    "    return np.argmax(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for title in titles:\n",
    "    print(getPred(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.0, subjectivity=0.25)\n",
      "Sentiment(polarity=0.0, subjectivity=0.25)\n",
      "Sentiment(polarity=0.0, subjectivity=0.25)\n",
      "Sentiment(polarity=0.06818181818181818, subjectivity=0.45)\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "Sentiment(polarity=0.0, subjectivity=0.06666666666666667)\n",
      "Sentiment(polarity=0.21428571428571427, subjectivity=0.42857142857142855)\n",
      "Sentiment(polarity=-0.1875, subjectivity=0.3875)\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "for title in titles:\n",
    "    print(TextBlob(title).sentiment)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.07\n",
      "0.0\n",
      "0.0\n",
      "0.145\n",
      "0.113\n",
      "0.174\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for title in titles:\n",
    "    sent = sentiment.polarity_scores(title)[\"pos\"]\n",
    "    print(sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
