{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Prev Close</th>\n",
       "      <th>Prev Open</th>\n",
       "      <th>PrevOPDiff</th>\n",
       "      <th>Prev High</th>\n",
       "      <th>Prev Low</th>\n",
       "      <th>Prev Volume</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>205.13</td>\n",
       "      <td>209.40</td>\n",
       "      <td>204.86</td>\n",
       "      <td>208.73</td>\n",
       "      <td>1107663</td>\n",
       "      <td>207.36</td>\n",
       "      <td>207.26</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>208.80</td>\n",
       "      <td>204.81</td>\n",
       "      <td>915486.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-06</td>\n",
       "      <td>209.96</td>\n",
       "      <td>211.80</td>\n",
       "      <td>208.13</td>\n",
       "      <td>209.25</td>\n",
       "      <td>1855578</td>\n",
       "      <td>208.73</td>\n",
       "      <td>205.13</td>\n",
       "      <td>-3.60</td>\n",
       "      <td>209.40</td>\n",
       "      <td>204.86</td>\n",
       "      <td>1107663.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-07</td>\n",
       "      <td>209.25</td>\n",
       "      <td>209.51</td>\n",
       "      <td>204.38</td>\n",
       "      <td>206.33</td>\n",
       "      <td>1232292</td>\n",
       "      <td>209.25</td>\n",
       "      <td>209.96</td>\n",
       "      <td>0.71</td>\n",
       "      <td>211.80</td>\n",
       "      <td>208.13</td>\n",
       "      <td>1855578.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>205.88</td>\n",
       "      <td>206.59</td>\n",
       "      <td>203.79</td>\n",
       "      <td>205.18</td>\n",
       "      <td>1077593</td>\n",
       "      <td>206.33</td>\n",
       "      <td>209.25</td>\n",
       "      <td>2.92</td>\n",
       "      <td>209.51</td>\n",
       "      <td>204.38</td>\n",
       "      <td>1232292.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-09</td>\n",
       "      <td>205.13</td>\n",
       "      <td>207.66</td>\n",
       "      <td>201.58</td>\n",
       "      <td>202.84</td>\n",
       "      <td>1637153</td>\n",
       "      <td>205.18</td>\n",
       "      <td>205.88</td>\n",
       "      <td>0.70</td>\n",
       "      <td>206.59</td>\n",
       "      <td>203.79</td>\n",
       "      <td>1077593.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Open    High     Low   Close   Volume  Prev Close  Prev Open  \\\n",
       "0  2014-01-03  205.13  209.40  204.86  208.73  1107663      207.36     207.26   \n",
       "1  2014-01-06  209.96  211.80  208.13  209.25  1855578      208.73     205.13   \n",
       "2  2014-01-07  209.25  209.51  204.38  206.33  1232292      209.25     209.96   \n",
       "3  2014-01-08  205.88  206.59  203.79  205.18  1077593      206.33     209.25   \n",
       "4  2014-01-09  205.13  207.66  201.58  202.84  1637153      205.18     205.88   \n",
       "\n",
       "   PrevOPDiff  Prev High  Prev Low  Prev Volume  Time  \n",
       "0       -0.10     208.80    204.81     915486.0     0  \n",
       "1       -3.60     209.40    204.86    1107663.0     1  \n",
       "2        0.71     211.80    208.13    1855578.0     2  \n",
       "3        2.92     209.51    204.38    1232292.0     3  \n",
       "4        0.70     206.59    203.79    1077593.0     4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Dataset/WiproClean.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[['Open', 'Close', 'High', 'Low', 'Volume']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = df['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(scaled_features) * 0.8)\n",
    "train_data, val_data = scaled_features[:train_size], scaled_features[train_size:]\n",
    "train_dates, val_dates = dates[:train_size], dates[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, dates, sequence_length):\n",
    "    X, y, seq_dates = [], [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:i+sequence_length])\n",
    "        y.append(data[i+sequence_length][1])  # Closing price is at index 1\n",
    "        seq_dates.append(dates[i+sequence_length])\n",
    "    return np.array(X), np.array(y), np.array(seq_dates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = len(val_data) - 1\n",
    "\n",
    "# Choose the sequence length (not exceeding the maximum sequence length)\n",
    "sequence_length = min(30, max_sequence_length)\n",
    "\n",
    "# Create input sequences for training and validation\n",
    "X_train, y_train, train_seq_dates = create_sequences(train_data, train_dates, sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(sequence_length, 5)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "58/58 [==============================] - 2s 13ms/step - loss: 0.0027\n",
      "Epoch 2/10\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 2.4160e-04\n",
      "Epoch 3/10\n",
      "58/58 [==============================] - 1s 13ms/step - loss: 2.1881e-04\n",
      "Epoch 4/10\n",
      "58/58 [==============================] - 1s 13ms/step - loss: 2.0200e-04\n",
      "Epoch 5/10\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 2.0795e-04\n",
      "Epoch 6/10\n",
      "58/58 [==============================] - 1s 13ms/step - loss: 1.9130e-04\n",
      "Epoch 7/10\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 1.7089e-04\n",
      "Epoch 8/10\n",
      "58/58 [==============================] - 1s 13ms/step - loss: 1.7954e-04\n",
      "Epoch 9/10\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 1.9676e-04\n",
      "Epoch 10/10\n",
      "58/58 [==============================] - 1s 13ms/step - loss: 1.7750e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a87d31e6d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "73/73 [==============================] - 3s 13ms/step - loss: 0.0084\n",
      "Epoch 2/10\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 5.2079e-04\n",
      "Epoch 3/10\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 4.6983e-04\n",
      "Epoch 4/10\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 4.7986e-04\n",
      "Epoch 5/10\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 4.3349e-04\n",
      "Epoch 6/10\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 3.6651e-04\n",
      "Epoch 7/10\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 3.5876e-04\n",
      "Epoch 8/10\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 3.4273e-04\n",
      "Epoch 9/10\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 3.2432e-04\n",
      "Epoch 10/10\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.9124e-04\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001A87F8B4EA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 335ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.44207016]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "\n",
    "\n",
    "# Extract the relevant features (Open, Close, High, Low, Volume)\n",
    "features = df[['Open', 'Close', 'High', 'Low', 'Volume']]\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "\n",
    "\n",
    "# Define the sequence length (number of historical data points to consider)\n",
    "sequence_length = 30\n",
    "\n",
    "# Function to create input sequences\n",
    "def create_sequences(data, sequence_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:i+sequence_length])\n",
    "        y.append(data[i+sequence_length][1])  # Closing price is at index 1\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create input sequences\n",
    "X, y = create_sequences(scaled_features, sequence_length)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(sequence_length, 5)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=10, batch_size=32)\n",
    "\n",
    "# Make predictions for the desired timeframe\n",
    "prediction_start_date = '2023-07-20'\n",
    "prediction_end_date = '2023-07-31'\n",
    "\n",
    "# Prepare the input data for prediction\n",
    "prediction_data = scaled_features[-sequence_length:]\n",
    "X_pred = np.array([prediction_data])\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.predict(X_pred)\n",
    "\n",
    "# Denormalize the predictions\n",
    "\n",
    "predictions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
